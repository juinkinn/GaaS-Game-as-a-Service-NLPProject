{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39d5bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ea3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26ac8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7118be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk1.csv')\n",
    "chunk2 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk2.csv')\n",
    "chunk3 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk3.csv')\n",
    "chunk4 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk4.csv')\n",
    "chunk5 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk5.csv')\n",
    "chunk6 = pd.read_csv('raw_data/train-balanced-sarcasm_chunk6.csv')\n",
    "\n",
    "df = pd.concat([chunk1, chunk2, chunk3, chunk4, chunk5, chunk6], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a8f3f",
   "metadata": {},
   "source": [
    "Filter only sarcasm comment and long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51be7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'] == 1]\n",
    "df = df[df['comment'].str.len() > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e77dc3",
   "metadata": {},
   "source": [
    "Filter game comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882ae3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_subreddits = [\n",
    "    'gaming', 'pcgaming', 'games', 'leagueoflegends', 'Overwatch',\n",
    "    'GlobalOffensive', 'FortNiteBR', 'PS4', 'xboxone', 'wow', 'nintendo', 'Minecraft'\n",
    "]\n",
    "\n",
    "df_game = df[df['subreddit'].isin(game_subreddits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9830ee",
   "metadata": {},
   "source": [
    "Select only ```comment``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f80f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game = df_game[['comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfab5f9",
   "metadata": {},
   "source": [
    "Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76450d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_game.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game = df_game.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6cc48",
   "metadata": {},
   "source": [
    "Check missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23de2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_game.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e871cf8",
   "metadata": {},
   "source": [
    "Normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e19a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "\n",
    "    # remove 'early access review' at the beginning\n",
    "    text = re.sub(r\"^(early access review[\\s:\\-–—)]*)\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # remove URLs, mentions, hashtags\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "\n",
    "    # remove numbers\n",
    "    #text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # remove emojis and icons\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "\n",
    "    # Remove spam patterns: no more than 3 consecutive identical characters\n",
    "    # e.g., \"goooood\" → \"good\", \"aaaaawesome\" → \"awesome\"\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1\\1', text)  # Keep up to 3 repeats\n",
    "    \n",
    "    # remove non-printable or control characters + double quotes\n",
    "    text = ''.join(\n",
    "        c for c in text \n",
    "        if unicodedata.category(c)[0] != 'C' and c.isprintable() and c != '\"'\n",
    "    )\n",
    "\n",
    "    # normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # remove duplicate consecutive words\n",
    "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n",
    "\n",
    "    # keep only ASCII characters (English text only)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Apply to the DataFrame\n",
    "df_game['comment'] = df_game['comment'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad08ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game\n",
    "df_game.to_csv('sarcasm_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7614629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06f6cd",
   "metadata": {},
   "source": [
    "Label comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sarcasm_raw.csv\")\n",
    "results = []\n",
    "\n",
    "if os.path.exists(\"sarcasm_labeled.csv\"):\n",
    "    dups = pd.read_csv(\"sarcasm_labeled.csv\")\n",
    "    for _, row in dups.iterrows():\n",
    "        results.append(row)\n",
    "else:\n",
    "    with open(\"sarcasm_labeled.csv\", \"w\",newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['comment', 'user_suggestion'])\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"api_key\"))\n",
    "\n",
    "\n",
    "# Process unprocessed rows in batches\n",
    "for idx, row in df.iterrows():\n",
    "    if idx < len(results):\n",
    "        continue\n",
    "\n",
    "    prompt = (\n",
    "        'Your role is do sentiment analysis on sarcastic comments from social medias on topic relating to video games.\\n'\n",
    "\n",
    "        'If the comment is positive, return the number \"1\"\\n'\n",
    "\n",
    "        'If the comment is negative, return the number \"0\"\\n'\n",
    "\n",
    "        'Return only the sentiment result and nothing else.\\n'\n",
    "\n",
    "        'Here is the comment:\\n'\n",
    "\n",
    "        f'{row[\"comment\"]}'\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "\n",
    "    #Extract response and parse JSON\n",
    "    try:\n",
    "        response_data = int(completion.choices[0].message.content)\n",
    "        print(idx,response_data)\n",
    "\n",
    "        with open(\"sarcasm_labeled.csv\", \"a\",newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([row['comment'], response_data])\n",
    "\n",
    "\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing response. Skipping.\")\n",
    "\n",
    "print(\"Processing complete! Only new rows were added.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
