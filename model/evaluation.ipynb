{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T03:27:42.841431Z",
     "iopub.status.busy": "2025-04-22T03:27:42.841200Z",
     "iopub.status.idle": "2025-04-22T03:28:14.388583Z",
     "shell.execute_reply": "2025-04-22T03:28:14.387797Z",
     "shell.execute_reply.started": "2025-04-22T03:27:42.841399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huhyhuvinh/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-11 11:24:20.646523: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 11:24:20.658667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746937460.673781   12362 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746937460.679052   12362 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746937460.695087   12362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746937460.695112   12362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746937460.695113   12362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746937460.695114   12362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-11 11:24:20.701400: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-22T03:29:49.968411Z",
     "iopub.status.busy": "2025-04-22T03:29:49.967448Z",
     "iopub.status.idle": "2025-04-22T03:30:22.449265Z",
     "shell.execute_reply": "2025-04-22T03:30:22.448615Z",
     "shell.execute_reply.started": "2025-04-22T03:29:49.968378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/huhyhuvinh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilbert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7747    0.7703    0.7725      3348\n",
      "           1     0.6149    0.6208    0.6179      1978\n",
      "\n",
      "    accuracy                         0.7148      5326\n",
      "   macro avg     0.6948    0.6956    0.6952      5326\n",
      "weighted avg     0.7154    0.7148    0.7151      5326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Distilbert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8944    0.9259    0.9099      3348\n",
      "           1     0.8667    0.8150    0.8400      1978\n",
      "\n",
      "    accuracy                         0.8847      5326\n",
      "   macro avg     0.8805    0.8704    0.8750      5326\n",
      "weighted avg     0.8841    0.8847    0.8839      5326\n",
      "\n",
      "Vader\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9040    0.4050    0.5594      3348\n",
      "           1     0.4794    0.9272    0.6320      1978\n",
      "\n",
      "    accuracy                         0.5989      5326\n",
      "   macro avg     0.6917    0.6661    0.5957      5326\n",
      "weighted avg     0.7463    0.5989    0.5864      5326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download VADER lexicon\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"../data/test.csv\")\n",
    "texts = df[\"user_review\"].astype(str).tolist()\n",
    "labels = df[\"user_suggestion\"].tolist()\n",
    "\n",
    "### 1. DISTILBERT Evaluation\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)  # Use GPU if available\n",
    "\n",
    "predictions = classifier(texts, truncation=True, padding=True)\n",
    "label_map = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "bert_preds = [label_map[p[\"label\"]] for p in predictions]\n",
    "\n",
    "print(\"Distilbert\")\n",
    "print(classification_report(labels, bert_preds, digits=4))\n",
    "\n",
    "### 2. Finetuned DistilBERT\n",
    "\n",
    "load_dotenv()\n",
    "hf_token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "checkpoint = \"GaaS-Team/DistilBERT-finetuned-GaaS\"\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(checkpoint, token=hf_token)\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, token=hf_token)\n",
    "ft_classifier = pipeline(\"sentiment-analysis\", model=ft_model, tokenizer=ft_tokenizer)  # Use GPU if available\n",
    "\n",
    "ft_predictions = ft_classifier(texts, truncation=True, padding=True)\n",
    "ft_preds = [label_map[p[\"label\"]] for p in ft_predictions]\n",
    "\n",
    "print(\"Finetuned Distilbert\")\n",
    "print(classification_report(labels, ft_preds, digits=4))\n",
    "\n",
    "### 3. VADER Evaluation\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_to_label(text):\n",
    "    score = vader.polarity_scores(text)[\"compound\"]\n",
    "    return 1 if score >= 0 else 0  # 1 = positive, 0 = negative\n",
    "\n",
    "vader_preds = [vader_to_label(text) for text in texts]\n",
    "\n",
    "print(\"Vader\")\n",
    "print(classification_report(labels, vader_preds, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7215910,
     "sourceId": 11508332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
